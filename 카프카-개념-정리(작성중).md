## 구조
* Kafka는 발행-구독(publish-subscribe) 모델을 기반으로 동작하며 크게 producer, consumer, broker로 구성된다.
* 확장성 / 고가용성을 위해 브로커들을 클러스터로 구성 동작.
![image](https://t1.daumcdn.net/cfile/tistory/2168D844588048A223)
## 기본 동작
* producer 특정 topic 메시지를 생성 전달 -> Broker 분산처리 (Zookepper) Topic 별로 적재(Topic 은 파티션별로 쪼개져 각서버에 분산) -> 해당 Topic 을 구독하는 Consumer 가 메시지를 가져가서 처리

## 설명
### Producers
  - 메시지 송신 API
  - 특정 Topic에 해당하는 메시지를 생성하는 프로세스, 메시지를 Broker에 전달(발행/Publish)
  - Producers는 데이터를 그들이 선택한 Topic으로 publish한다.
  - Producer가 메시지를 실제로 어떤 partition으로 전송할지는 사용자가 구현한 partition 분배 알고리즘에 의해 결정된다. 예를 들어 라운드-로빈 방식의 partition 분배 알고리즘을 구현하여 각 partition에 메시지를 균등하게 분배하도록 하거나, 메시지의 키를 활용하여 알파벳 A로 시작하는 키를 가진 메시지는 P0에만 전송하고, B로 시작하는 키를 가진 메시지는 P1에만 전송하는 형태의 구성도 가능하다.

### Consumer
  - 메시지 수신 API
  - Broker에게서 구독(Subscribe)하는 Topic의 메시지를 가져와 사용(처리)하는 프로세스
  - Topic 당 할당된 스레드 개수만큼 스레드가 만들어지면 Partition 으로부터 메세지를 읽음.
  - 하나의 스레드는 1개 이상 partition 으로 부터 메시지를 읽을 수 있다.
  - public void run 메소드 내 while(is.hasNext())에서 블록킹돼 있다가 파티션으로 메시지가 들어오면 이 곳에서 메시지를 읽는다. 따라서 다른 타겟으로 메시지를 처리하는 데 적합한 장소라고 할 수 있다. 즉 메시지를 파일로 저장하던지 대용량 입력이 가능한 하둡이나 NoSQL로 저장하기에 유용하다.

### Broker
  - 토픽을 기준으로 메시지 관리
  - broker 는 클러스터로 구성 (이에 대한 분산 처리는 zookeeper 가 처리)
  - Producers와 Consumers가 만날 수 있도록 메시지를 관리하는 서버 클러스터로 Producer에게서 전달받은 메시지를 Topic별로 분류한다. 
  - 여러대의 Broker Cluster로 구성 가능하며, Zookeeper에 의해 각 노드가 모니터링 된다.

### Topic
  - 발행(Publish)된 메시지들의 category
  - 유사한 메시지들의 집합이다. 프로듀서는 메시지를 전달할 토픽을 반드시 지정해야 한다.
  - partition 단위로 클러스터 각 서버들에 분산 저장
  - 각 partition 은 0부터 1씩 증가하는 offset 값을 메시지에 부여 (partition 내 메시지 식별)
  - 클러스터내 메시지들은 설정된 기간동안 유지 후 삭제됨.

## 기존의 메시징과 차이점
  - 기존 broker -> consumer 로 push 카프카 반대로 pull 로 땡겨옴.
  - 이로 인해 필요한 메시지만 broker 에서 가져오므로 최적의 성능. 그리고 pull 방식이라 batch 처리 구현 가능.
  - 카프카는 파일로 저장 연속성 상승 (대용량에 적합) - HDD 의 순차읽기는 SSD에 7배 정도만 느리다.
  - AMQP 프로토콜이나 JMS API를 사용하지 않고 단순한 메시지 헤더를 지닌 TCP기반의 프로토콜을 사용하여 오버헤드 감소